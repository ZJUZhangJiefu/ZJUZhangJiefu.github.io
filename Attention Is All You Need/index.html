
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="大观散人">
      
      
        <link rel="canonical" href="https://ZJUZhangJiefu.github.io/Attention%20Is%20All%20You%20Need/">
      
      
        <link rel="prev" href="../A%20Gentle%20Introduction%20to%20Graph%20Neural%20Networks/">
      
      
        <link rel="next" href="../DDPM/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.6">
    
    
      
        <title>Attention Is All You Need(NIPS 2017) - 大观散人的博客</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.50c56a3b.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=仿宋:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"仿宋";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="cyan" data-md-color-accent="cyan">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#attention-is-all-you-neednips-2017" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href=".." title="大观散人的博客" class="md-header__button md-logo" aria-label="大观散人的博客" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            大观散人的博客
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Attention Is All You Need(NIPS 2017)
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="cyan" data-md-color-accent="cyan"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="cyan" data-md-color-accent="cyan"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/ZJUZhangJiefu/ZJUZhangJiefu.github.io" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ZJUZhangJiefu.github.io
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
    
  
  主页

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../CP/" class="md-tabs__link">
          
  
  计算机专业课

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      
  
  
    
  
  
    
    
      
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../RealNVP/" class="md-tabs__link">
          
  
  深度学习论文

        </a>
      </li>
    
  

    
  

    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../RL/" class="md-tabs__link">
          
  
  深度学习专题

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="大观散人的博客" class="md-nav__button md-logo" aria-label="大观散人的博客" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    大观散人的博客
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/ZJUZhangJiefu/ZJUZhangJiefu.github.io" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ZJUZhangJiefu.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    主页
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    计算机专业课
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            计算机专业课
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../CP/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    编译原理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../OS-Notes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    操作系统
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    计算机视觉
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            计算机视觉
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Camera%20Model%20and%203D%20Vision/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    专题汇编——相机模型与立体视觉
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../CV-Notes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    复习提纲全解
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../SE/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    软件工程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../NA-Notes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数值分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../AOR-Notes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    应用运筹学基础
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    深度学习论文
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            深度学习论文
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    深度生成模型
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            深度生成模型
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    流模型
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            流模型
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../RealNVP/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RealNVP
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_2" >
        
          
          <label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    GNN
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            GNN
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../A%20Gentle%20Introduction%20to%20Graph%20Neural%20Networks/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    图神经网络导论
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Transformer
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Transformer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Attention Is All You Need(NIPS 2017)
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Attention Is All You Need(NIPS 2017)
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#abstract" class="md-nav__link">
    <span class="md-ellipsis">
      Abstract
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      1 Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-background" class="md-nav__link">
    <span class="md-ellipsis">
      2 Background
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-model-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      3 Model Architecture
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-why-self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      4 Why Self-Attention
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-training" class="md-nav__link">
    <span class="md-ellipsis">
      5 Training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-results" class="md-nav__link">
    <span class="md-ellipsis">
      6 Results
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      7 Conclusion
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    扩散模型
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            扩散模型
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../DDPM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Denoising Diffusion Probabilistic Models
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" >
        
          
          <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    优化器
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5">
            <span class="md-nav__icon md-icon"></span>
            优化器
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Descending%20Through%20A%20Crowded%20Valley/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Descending Through A Crowded Valley
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6" >
        
          
          <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    分子对接
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_6">
            <span class="md-nav__icon md-icon"></span>
            分子对接
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../DSDP/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DSDP - A Blind Docking Strategy Accelerated by GPUs
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_7" >
        
          
          <label class="md-nav__link" for="__nav_3_7" id="__nav_3_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    逆合成预测
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_7">
            <span class="md-nav__icon md-icon"></span>
            逆合成预测
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../G2GT/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    G2GT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../O-GNN/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    O-GNN
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    深度学习专题
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            深度学习专题
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../RL/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    强化学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../DGM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    深度生成模型基础
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#abstract" class="md-nav__link">
    <span class="md-ellipsis">
      Abstract
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      1 Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-background" class="md-nav__link">
    <span class="md-ellipsis">
      2 Background
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-model-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      3 Model Architecture
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-why-self-attention" class="md-nav__link">
    <span class="md-ellipsis">
      4 Why Self-Attention
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-training" class="md-nav__link">
    <span class="md-ellipsis">
      5 Training
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-results" class="md-nav__link">
    <span class="md-ellipsis">
      6 Results
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      7 Conclusion
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="attention-is-all-you-neednips-2017"><code>Attention Is All You Need(NIPS 2017)</code></h1>
<h2 id="abstract"><code>Abstract</code></h2>
<p>1.主流序列转录模型  <br />
（1）序列转录<br />
·输入一个序列，输出另一个序列。<br />
·举例：机器翻译<br />
（2）主流序列转录模型的设计<br />
①基于复杂的循环架构。<br />
②包含编码器、解码器的卷积神经网络。<br />
（3）当前表现最佳的序列转录模型<br />
·通过注意力机制，连接编码器、解码器。<br />
2.新型简单架构——<code>Transformer</code>的提出<br />
（1）架构设计<br />
·仅基于注意力机制，完全摒弃循环和卷积。<br />
（2）模型在机器翻译任务上的表现<br />
·高性能，并行化程度提高，训练时间大幅减少。<br />
·<code>WMT 2014 English-to-German</code>翻译任务：获得<code>28.4 BLEU score</code>，比之前最佳的结果提升<code>2 BLEU</code>。<br />
·<code>WMT 2014 English-to-French</code>翻译任务：获得最新的单模型<code>SOTA</code>分数<code>41.8 BLEU</code>，只需在<code>8</code>块<code>GPU</code>上训练<code>3.5</code>天。<br />
（3）模型的泛化能力<br />
·提供大型/有限训练数据，<code>Transformer</code>在英语成分分析(<code>English constituency parsing</code>)上表现好，说明<code>Transformer</code>可以较好地泛化到其他任务。    </p>
<h2 id="1-introduction"><code>1 Introduction</code></h2>
<p>1.循环神经网络<br />
（1）序列建模与转录任务的<code>SOTA</code>模型<br />
·循环神经网络（特别是长短时记忆、门控循环神经网络），被坚固地确定为序列建模与转录任务（如：语言建模、机器翻译）的<code>SOTA</code>模型。<br />
·大量尝试持续推动着循环语言模型、编码器-解码器架构的边界。<br />
（2）模型的不足<br />
·循环模型沿着输入/输出符号的位置进行计算，并将符号位置与计算时间步对齐。<br />
·循环模型通过前序隐藏状态<span class="arithmatex">\(h_{t - 1}\)</span>以及位置<span class="arithmatex">\(t\)</span>的输入，生成一系列隐藏状态<span class="arithmatex">\(h_t\)</span>。<br />
·循环模型的序列化本质阻碍了训练样本的并行化。 
·近期工作通过分解技巧、条件计算，实现了计算效率和模型性能的提高，但序列化计算的基本限制仍然存在。<br />
2.注意力机制<br />
·作为序列建模与转录模型的不可或缺部分，可以建模两个元素的依赖关系，并且不受它们在输入/输出序列中的距离的影响。<br />
·在几乎所有情况下，注意力机制与循环神经网络协同使用。<br />
3.本文提出的<code>Transformer</code>架构<br />
·避开循环架构，完全依赖于注意力机制，以描绘输入、输出间的全局依赖关系。<br />
·大幅度提升并行化程度，并实现更高的翻译质量。  </p>
<h2 id="2-background"><code>2 Background</code></h2>
<p>1.使用卷积减少序列化计算<br />
（1）模型举例：<code>Extended Neural GPU/ByteNet/ConvS2S</code>。<br />
（2）共同点：使用卷积神经网络作为基本块，并行计算各个输入/输出位置的隐藏表示。<br />
（3）不足：随着两个输入/输出位置之间距离的增大，计算二者关联的操作数量也会增大，这导致学习远距离位置之间的依赖性更加困难。  （4）<code>Transformer</code>对上述问题的解决：只需常数操作即可获得任意两个位置之间的关联性，代价是由注意力权重平均(<code>averaging attention-weighted positions</code>)导致的有效分辨率下降。  <br />
2.自注意力/内部注意力机制<br />
·一种注意力机制，联系一个输入序列的不同位置，以生成序列的一种表示。<br />
·成功应用于大量任务，如阅读理解、抽象摘要、文本蕴含，以及学习任务相关的序列表示等。<br />
3.端到端记忆网络<br />
·基于循环注意力机制，而非序列对齐的循环。<br />
·在单语言问题回答、语言建模任务上表现较好。<br />
4.<code>Transformer</code>架构<br />
·第一个完全依赖于自注意力机制的模型，不使用序列对齐的<code>RNN</code>或卷积。  </p>
<h2 id="3-model-architecture"><code>3 Model Architecture</code></h2>
<p>1.最优竞争力的序列转录模型——编码器-解码器架构<br />
·编码器：将输入序列<span class="arithmatex">\((x_1, \cdots, x_n)\)</span>映射为连续表示<span class="arithmatex">\((z_1, \cdots, z_n)\)</span>。<br />
·解码器：给定<span class="arithmatex">\(\mathbf{z}\)</span>，一次一个元素地生成输出序列<span class="arithmatex">\((y_1, \cdots, y_m)\)</span>。<br />
·解码器的每一步骤都是自回归的，将之前已生成的符号作为额外的输入。<br />
2.<code>Transformer</code>架构<br />
<img alt="" src="../assets/DL/1.JPG" /><br />
·编码器、解码器：均使用堆叠的子注意力机制，以及逐点(<code>point-wise</code>)全连接网络。<br />
（1）编码器<br />
·共<code>6</code>个相同层次。<br />
·每个层次有两个子层，分别是：多头自注意力机制、逐位置全连接前馈神经网络。<br />
·每个子层均使用残差连接，以及层正则化(<code>layer normalization</code>)，即<code>LayerNorm(x + Sublayer(x))</code>，其中<code>Sublayer(x)</code>即为子层实现的函数。<br />
[注1]<code>Batchnorm</code>针对<code>batch</code>作正则化，<code>Layernorm</code>针对样本作正则化。<br />
[注2]在时序模型中，<code>Layernorm</code>比<code>Batchnorm</code>更常用，原因是各序列样本长度可能不同，故<code>Batchnorm</code>抖动较大，且不能处理长于训练序列的测试序列。<br />
·模型的每个子层，以及嵌入(<code>embedding</code>)层，输出的维度均为<span class="arithmatex">\(d_{model} = 512\)</span>。<br />
[注]在各个层次中，每个词元均使用<code>512</code>个维度进行表示。<br />
（2）注意力机制<br />
①注意力函数<br />
·将一个查询(<code>query</code>)，以及一组键值对(<code>key-value pair</code>)，映射到一个输出。<br />
·输出：<code>value</code>的加权和，权重由<code>query</code>和相应<code>key</code>的相似度函数进行计算。<br />
②缩放点积注意力(<code>Scaled Dot-Product Attention</code>)<br />
<img alt="" src="../assets/DL/2.JPG" /><br />
·输入：<code>query, key</code>的维度均为<span class="arithmatex">\(d_k\)</span>，<code>value</code>的维度均为<span class="arithmatex">\(d_v\)</span>。<br />
·计算步骤：首先计算<code>query</code>和所有<code>key</code>的相似度，对每个相似度除以<span class="arithmatex">\(\sqrt{d_k}\)</span>，然后应用<code>softmax</code>函数以获得<code>value</code>的权重。<br />
·实际运行：将一组<code>query</code>打包成一个矩阵<span class="arithmatex">\(Q\)</span>，并将<code>key, value</code>分别记为矩阵<span class="arithmatex">\(K, V\)</span>。<br />
·数学公式：<span class="arithmatex">\(Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V\)</span><br />
[理解]<br />
设<code>query</code>个数为<span class="arithmatex">\(n\)</span>，键值对个数为<span class="arithmatex">\(m\)</span>，则各矩阵的形状为：<br />
<span class="arithmatex">\(Q_{n \times d_k}, K_{m \times d_K}, V_{m \times d_v}\)</span><br />
·缩放点积注意力：在点击注意力基础上添加缩放因子<span class="arithmatex">\(\frac{1}{\sqrt{d_k}}\)</span>。<br />
·加性注意力：使用带一个隐藏层的前馈神经网络计算相似度。<br />
·点积注意力：计算速度更快、空间效率更高，原因是矩阵乘法可以高度优化、并行。<br />
·两种注意力的性能：加性注意力的性能优于不含缩放因子的点积注意力的性能。<br />
·设计缩放因子的原因：对于较大的<span class="arithmatex">\(d_k\)</span>，点积数值也会增大，导致<code>softmax</code>函数梯度很小。<br />
（3）多头注意力(<code>Multi-Head Attention</code>)<br />
<img alt="" src="../assets/DL/3.JPG" /><br />
①架构<br />
·对<code>query, key, value</code>进行<span class="arithmatex">\(h\)</span>次不同的线性投影，分别投影到<span class="arithmatex">\(d_k, d_k, d_v\)</span>维度。<br />
·各个投影可通过学习得到，可以并行计算注意力函数，获得<span class="arithmatex">\(d_v\)</span>维度的输出值。<br />
·输出值先合并，再投影，获得最终输出。<br />
②作用<br />
·允许模型同时关注不同位置、不同表示空间的信息。<br />
③数学公式<br />
·<span class="arithmatex">\(MultiHead(Q, K, V) = Concat(head_1, \cdots, head_h)W^O\)</span><br />
·<span class="arithmatex">\(head_i = Attention(QW_i^Q, KW_i^K, VW_i^V)\)</span><br />
·<span class="arithmatex">\(W_i^Q \in \mathbf{R}^{d_{model} \times d_k}, W_i^K \in \mathbf{R}^{d_{model} \times d_k}, 
W_i^V \in \mathbf{R}^{d_{model} \times d_v}, 
W^O \in \mathbf{R}^{hd_v \times d_{model}}\)</span><br />
·实验参数设置：<span class="arithmatex">\(h = 8, d_k = d_v = \frac{d_{model}}{h} = 64\)</span><br />
·由于每个<code>head</code>的维度均降低，因此<code>multi-head</code>注意力的总计算代价与<code>single-head</code>注意力相当。<br />
（4）位置相关的前馈神经网络(<code>PositionWise Feed-Forward Network</code>)<br />
·编码器/解码器的每个层次都包含一个全连接前馈神经网络。<br />
·该网络针对每个位置分别进行相同的计算。 
·数学公式：<span class="arithmatex">\(FFN(x) = max(0, xW_1 + b_1)W_2 + b_2\)</span>
·上述公式中，<span class="arithmatex">\(max(0, xW_1 + b_1)\)</span>即表示对<span class="arithmatex">\(xW_1 + b_1\)</span>应用<code>relu</code>函数。<br />
·本质：两个卷积核大小为<span class="arithmatex">\(1\)</span>的卷积层，分别针对每个位置/词元进行作用。<br />
·维度变化：<span class="arithmatex">\(x \rightarrow xW_1 + b_1\)</span>由<span class="arithmatex">\(512\)</span>维变为<span class="arithmatex">\(2048\)</span>维；<span class="arithmatex">\(xW_1 + b_1 \rightarrow max(0, xW_1 + b_1)W_2 + b_2\)</span>由<span class="arithmatex">\(2048\)</span>维恢复到<span class="arithmatex">\(512\)</span>维。<br />
[注]<br />
·本质上，<code>MLP</code>的作用是语义空间转换。<br />
（5）嵌入与<code>Softmax</code><br />
·使用预训练嵌入，将输入、输出词元(<code>token</code>)转化为<span class="arithmatex">\(d_{model}\)</span>维度的向量。<br />
·使用预训练线性转化、<code>softmax</code>函数，转化解码器输出，以预测下一词元的概率。<br />
·两个<code>embedding</code>层、<code>pre-softmax</code>线性变换共享权重。<br />
·由于维度较大时，各权重偏小，因此对于<code>embedding</code>层，将权重乘以<span class="arithmatex">\(\sqrt{d_{model}}\)</span>。<br />
（6）位置编码<br />
·注意力机制本身不具有序列信息，通过位置编码注入词元相对/绝对位置信息。<br />
·在编码器、解码器图示的底部，位置编码与输入<code>embedding</code>相加。<br />
·位置编码与<code>embedding</code>具有相同的维度<span class="arithmatex">\(d_{model}\)</span>，可直接相加。<br />
·本实验的位置编码：<br />
<span class="arithmatex">\(PE_{(pos, 2i)} = sin(\frac{pos}{10000^{\frac{2i}{d_{model}}}})\)</span><br />
<span class="arithmatex">\(PE_{(pos, 2i + 1)} = cos(\frac{pos}{10000^{\frac{2i}{d_{model}}}})\)</span><br />
其中，<span class="arithmatex">\(pos\)</span>表示位置，<span class="arithmatex">\(i\)</span>表示维度序号。  </p>
<h2 id="4-why-self-attention"><code>4 Why Self-Attention</code></h2>
<p>1.自注意力机制与循环层、卷积层的对比<br />
<img alt="" src="../assets/DL/4.JPG" /><br />
·<span class="arithmatex">\(n\)</span>表示序列长度，<span class="arithmatex">\(d\)</span>表示向量的维度（即<span class="arithmatex">\(d_{model}\)</span>）。<br />
·由于矩阵乘法高度并行化，因此自注意力机制的顺序化操作数可视为<span class="arithmatex">\(O(1)\)</span>。<br />
·前向、后向路径的长度越短，越容易学习到长距离依赖关系。<br />
·循环层的问题：前向/反向信号的传递，最大路径长度为<span class="arithmatex">\(O(n)\)</span>，且顺序化操作数为<span class="arithmatex">\(O(n)\)</span>，并行化程度低。<br />
·限制自注意力：为了提升长序列任务的表现，自注意力可以进行限制，只考虑大小为<span class="arithmatex">\(r\)</span>的邻域；此时，最大路径长度变为<span class="arithmatex">\(O(\frac{n}{r})\)</span>。<br />
2.结论<br />
·自注意力模型更容易理解：独立的<code>attention heads</code>可以学习执行不同的任务，它们表现出的行为与句子语法、语义结构相关。  </p>
<h2 id="5-training"><code>5 Training</code></h2>
<p>1.训练数据和批量化<br />
·数据集：<code>WMT 2014 English-German</code>标准数据集，共包含约<code>4.5</code>百万个句子对。<br />
·各句子使用<code>byte-pair encoding</code>进行编码，对于约<code>37000</code>个词元使用共享的源-目标词汇表。<br />
·英语译法语任务：在<code>WMT 2014 English-French</code>数据集上训练，约包含<code>36M</code>个句子及大小为<code>32000</code>的<code>word-piece vocabulary</code>。<br />
·每个<code>training batch</code>包含一组句子对，这组句子对共有约<code>25000</code>个源词元，以及<code>25000</code>个目标词元。<br />
2.硬件和<code>schedule</code><br />
·设备：<code>8</code>块<code>P100</code>显卡。<br />
·基本模型训练用时：每个训练步骤需<code>0.4</code>秒，共训练<code>100, 000</code>步，<code>0.5</code>天。<br />
·大型模型训练用时：每个训练步骤需<code>1.0</code>秒，共训练<code>300, 000</code>个步骤，<code>3.5</code>天。<br />
3.优化器<br />
·优化器：使用超参数分别为<span class="arithmatex">\(\beta_1 = 0.9, \beta_2 = 0.98, \epsilon = 10^{-9}\)</span>的<code>Adam</code>优化器。<br />
·学习率：<span class="arithmatex">\(lrate = d_{model}^{-0.5}\cdot min(step\_num^{-0.5}, step\_num \cdot warmup\_steps^{-1.5})\)</span><br />
·首先，学习率线性增长；随后，学习率逐步下降。  <br />
·实验使用的<code>warm_up steps</code>：<code>4000</code>步。<br />
4.正则化 <br />
（1）残差<code>dropout</code><br />
·先对子层的输出进行<code>dropout</code>，再将其与子层输入相加，最后进行正则化。<br />
·对于编码器、解码器中<code>embedding</code>与位置编码之和，均使用<code>dropout</code>。<br />
·实验使用的<code>dropout rate</code>：<span class="arithmatex">\(P_{drop} = 0.1\)</span>。<br />
（2）标签平滑(<code>label smoothing</code>)<br />
·方法：将<span class="arithmatex">\(\epsilon_{ls} = 0.1\)</span>作为正确词元的概率阈值。<br />
·结果：模型更不易理解，训练结果更不确定，但是精度、<code>BLEU</code>分数有所提升。  </p>
<h2 id="6-results"><code>6 Results</code></h2>
<p>1.机器翻译
<img alt="" src="../assets/DL/5.JPG" /><br />
2.模型变种<br />
<img alt="" src="../assets/DL/6.JPG" /><br />
·目的：评估<code>Transformer</code>各组件的作用。<br />
·方法：使用束搜索(<code>beam search</code>)，不使用<code>checkpoint</code>平均。<br />
·变量：<code>attention head</code>的数目、<code>attention key-value</code>的维度。<br />
·更改变量时，保持总计算量不变。<br />
·结果：单个<code>head</code>、过多<code>head</code>均导致模型性能降低；降低注意力<code>key</code>的规模<span class="arithmatex">\(d_k\)</span>会损害模型的质量。<br />
·思考：确定相似度不是容易的，一个比点积更复杂的相似度函数可能带来好处。<br />
·模型规模：更大的模型性能更佳。<br />
·<code>dropout</code>：对于防止过拟合非常有帮助。<br />
·<code>learned</code>位置编码：与正弦位置编码效果相当。<br />
3.英语成分分析<br />
<img alt="" src="../assets/DL/7.JPG" /><br />
·目的：评估<code>Transformer</code>是否能泛化到其他任务。<br />
·英语成分分析任务的挑战：输出有明显的结构约束，并且明显长于输入。<br />
·结论：即使缺乏针对特定任务的微调，<code>transformer</code>模型表现极好，获得了比所有已知模型（<code>Recurrent Neural Network Grammar</code>除外）更好的性能。  </p>
<h2 id="7-conclusion"><code>7 Conclusion</code></h2>
<p>1.工作总结——<code>Transformer</code>架构<br />
（1）模型简介
·第一个完全基于注意力机制的序列转录模型。<br />
·使用多头注意力机制，替代编码器-解码器架构中最常用的循环层。<br />
（2）机器翻译任务的表现<br />
·与基于循环层或卷积层的架构相比，训练明显加快。<br />
·在<code>WMT 2014 English-to-German/WMT 2014 English-to-French</code>翻译任务上均取得新的<code>SOTA</code>。<br />
2.未来展望<br />
（1）<code>Transformer</code>应用于其他任务<br />
·将<code>Transformer</code>应用于文本以外的输入/输出形式。<br />
·研究局部、有限的注意力机制，以高效地处理图片、音频、视频等输入/输出形式。<br />
（2）减少生成结果的序列化程度  </p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.tabs.sticky", "header.autohide"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../assets/javascripts/bundle.e1c3ead8.min.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
      
    
  </body>
</html>